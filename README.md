# DeLiVR: Lie-Group Transformer for Video Deraining

This repository provides a PyTorch implementation of **DeLiVR** (Derain with Lie-group Video Restoration), a Lie-group Transformer tailored for video deraining tasks.


## ðŸ”” News

**DeLiVR** has been **accepted to ICLR 2026** ðŸŽ‰  

- Paper: *DeLiVR: Differential Spatiotemporal Lie Bias for Efficient Video Deraining*  
- OpenReview discussion: https://openreview.net/forum?id=W2eNfLmCHY
---

## 1. Data Layout

For paired video deraining (rainy â†’ clean), organize your dataset as:

```
/home/exp/dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ derain/                    # NTU dataset
â”‚   â”‚   â”œâ”€â”€ rainy/                 # input_dirname
â”‚   â”‚   â”‚   â”œâ”€â”€ seq001/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 0001.jpg
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 0002.jpg
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â””â”€â”€ seq002/
â”‚   â”‚   â””â”€â”€ gt/                    # target_dirname
â”‚   â”‚       â”œâ”€â”€ seq001/
â”‚   â”‚       â”‚   â”œâ”€â”€ 0001.jpg
â”‚   â”‚       â”‚   â””â”€â”€ ...
â”‚   â”‚       â””â”€â”€ seq002/
â”‚   â”œâ”€â”€ heavy/                     # Heavy rain dataset
â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ gt/
â”‚   â”œâ”€â”€ light/                     # Light rain dataset
â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ gt/
â”‚   â””â”€â”€ weatherbench/              # WeatherBench dataset
â”‚       â”œâ”€â”€ input/
â”‚       â””â”€â”€ target/
â”‚
â””â”€â”€ test/
    â”œâ”€â”€ derain/
    â”‚   â”œâ”€â”€ rainy/
    â”‚   â””â”€â”€ gt/
    â”œâ”€â”€ heavy/
    â”‚   â”œâ”€â”€ input/
    â”‚   â””â”€â”€ gt/
    â”œâ”€â”€ light/
    â”‚   â”œâ”€â”€ input/
    â”‚   â””â”€â”€ gt/
    â””â”€â”€ weatherbench/
        â”œâ”€â”€ input/
        â””â”€â”€ target/
```

### Supported Datasets

| Dataset | Train Path | Test Path | Input Dir | Target Dir |
|---------|------------|-----------|-----------|------------|
| NTU (Derain) | `/home/exp/dataset/train/derain` | `/home/exp/dataset/test/derain` | `rainy` | `gt` |
| Heavy Rain | `/home/exp/dataset/train/heavy` | `/home/exp/dataset/test/heavy` | `input` | `gt` |
| Light Rain | `/home/exp/dataset/train/light` | `/home/exp/dataset/test/light` | `input` | `gt` |
| WeatherBench | `/home/exp/dataset/train/weatherbench` | `/home/exp/dataset/test/weatherbench` | `input` | `target` |

---

## 2. Installation

```bash
pip install -r requirements.txt
```

Required packages:
- PyTorch >= 1.12
- torchvision
- numpy
- opencv-python
- pyyaml
- tensorboard
- tqdm

---

## 3. Configuration

All training parameters are specified in YAML config files under `src/config/`:

```
src/config/
  â”œâ”€â”€ derain_ntu.yaml         # NTU Derain dataset
  â”œâ”€â”€ derain_heavy.yaml       # Heavy rain dataset
  â”œâ”€â”€ derain_light.yaml       # Light rain dataset
  â””â”€â”€ derain_weatherbench.yaml # WeatherBench dataset
```

### Key Configuration Parameters

```yaml
# Data
data_root: /path/to/train/data
val_root: /path/to/test/data
input_dirname: rainy          # Input folder name
target_dirname: gt            # Ground truth folder name
T: 5                          # Number of temporal frames
crop_size: 256                # Training crop size

# Model
embed_dim: 128                # Embedding dimension
depth: 12                     # Number of transformer blocks
heads: 8                      # Number of attention heads
patch: 8                      # Patch size

# Lie Group
so3_mode: so2                 # so2 (planar) or so3 (full 3D)
angle_max_deg: 35.0           # Maximum rotation angle (degrees)

# Training
batch_size: 8
epochs: 8000
lr: 0.0002
warmup_epochs: 10
grad_clip: 0.5

# Losses
w_charb: 1.0                  # Charbonnier loss
w_ssim: 0.05                  # SSIM loss
w_fft: 0.05                   # FFT frequency loss
w_edge: 0.05                  # Edge loss
w_lievel: 0.01                # Lie velocity regularization

# EMA
use_ema: 1
ema_decay: 0.999
```

---

## 4. Training

### Single Dataset Training (Multi-GPU DDP)

```bash
cd /home/exp/ICLR-DeLiVR/lie-transformer

# NTU Derain
CUDA_VISIBLE_DEVICES=1,2,3,5,7 bash run_ddp.sh 5 --config src/config/derain_ntu.yaml

# Heavy Rain
CUDA_VISIBLE_DEVICES=1,2,3,5,7 bash run_ddp.sh 5 --config src/config/derain_heavy.yaml

# Light Rain
CUDA_VISIBLE_DEVICES=1,2,3,5,7 bash run_ddp.sh 5 --config src/config/derain_light.yaml

# WeatherBench
CUDA_VISIBLE_DEVICES=1,2,3,5,7 bash run_ddp.sh 5 --config src/config/derain_weatherbench.yaml
```

### Resume Training from Checkpoint

```bash
CUDA_VISIBLE_DEVICES=1,2,3,5,7 bash run_ddp.sh 5 \
    --config src/config/derain_ntu.yaml \
    --resume /home/exp/lie-transformer/runs_NTU_video/last.pth
```

---

## 5. Testing / Evaluation

```bash
python test_video.py \
    --config src/config/derain_ntu.yaml \
    --batch_size 2 \
    --gpu 3 \
    --checkpoint /home/exp/lie-transformer/runs_NTU_video/last.pth \
    --data_root /home/exp/dataset/test/derain
```

### Test Commands for Each Dataset

```bash
# NTU Derain
python test_video.py --config src/config/derain_ntu.yaml --batch_size 2 --gpu 3 \
    --checkpoint /home/exp/lie-transformer/runs_NTU_video/last.pth \
    --data_root /home/exp/dataset/test/derain

# Heavy Rain
python test_video.py --config src/config/derain_heavy.yaml --batch_size 2 --gpu 3 \
    --checkpoint /home/exp/lie-transformer/runs_Heavy_video/last.pth \
    --data_root /home/exp/dataset/test/heavy

# Light Rain
python test_video.py --config src/config/derain_light.yaml --batch_size 2 --gpu 3 \
    --checkpoint /home/exp/lie-transformer/runs_Light_video/last.pth \
    --data_root /home/exp/dataset/test/light

# WeatherBench
python test_video.py --config src/config/derain_weatherbench.yaml --batch_size 2 --gpu 3 \
    --checkpoint /home/exp/lie-transformer/runs_WeatherBench_video/last.pth \
    --data_root /home/exp/dataset/test/weatherbench
```

---

## 6. Project Structure

```
lie-transformer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ derain_ntu.yaml
â”‚   â”‚   â”œâ”€â”€ derain_heavy.yaml
â”‚   â”‚   â”œâ”€â”€ derain_light.yaml
â”‚   â”‚   â””â”€â”€ derain_weatherbench.yaml
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ video_derain.py         # Video dataset loader
â”‚   â”‚   â””â”€â”€ paired_image.py         # Image pair dataset
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ so3.py                  # SO(3) operations: hat, exp, log, SO3Head
â”‚   â”‚   â”œâ”€â”€ lie_attention.py        # Lie-aware positional encoding
â”‚   â”‚   â””â”€â”€ lie_transformer_net.py  # Full model: GDFN, CAB, LieTransformerNet
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ metrics.py              # PSNR, SSIM metrics
â”œâ”€â”€ train_video5.py                 # Main training script
â”œâ”€â”€ test_video.py                   # Evaluation script
â”œâ”€â”€ run_ddp.sh                      # DDP launch script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---


## 7. Citation

If you find this code useful, please consider citing:

```bibtex
@article{sun2025delivr,
  title={DeLiVR: Differential Spatiotemporal Lie Bias for Efficient Video Deraining},
  author={Sun, Shuning and Lu, Jialang and Chen, Xiang and Wang, Jichao and Lu, Dianjie and Zhang, Guijuan and Gao, Guangwei and Zheng, Zhuoran},
  journal={arXiv preprint arXiv:2509.21719},
  year={2025}
}
```

---

## 8. License

This project is released under the MIT License.
